{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de regresión\n",
    "\n",
    "Se quiere determinar la relación entre la concentración de cierto fármaco en el torrente sanguíneo y el tiempo transcurrido desde que se administró el fármaco. Se recopila datos sobre la concentración de la droga en el torrente sanguíneo en diferentes intervalos de tiempo después de la administración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/drug.csv\") # cargando los datos desde un csv\n",
    "dataset.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas nos da algunas herramientas de graficado\n",
    "plt.figure(figsize=(7, 5))\n",
    "#dataset.Time.hist()\n",
    "dataset[\"Time\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "dataset.Concentration.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos ver cual es la relacion entre ambas variables....\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "correlacion_drug = np.corrcoef(dataset[\"Time\"], dataset[\"Concentration\"])\n",
    "sns.heatmap(data=correlacion_drug, annot=True, annot_kws={\"size\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos el dataset\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(dataset['Time'], dataset['Concentration'] , color='r', marker=\"x\",s=60)\n",
    "plt.grid(True, linewidth=0.5)\n",
    "plt.xlabel('Tiempo [h]', fontsize=14)\n",
    "plt.ylabel('Concentración [mg/L]', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "plt.title('Dataset de concentración de droga vs. tiempo', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos y de hecho vemos que hay una relacion lineal entre las dos variables, por lo tanto asumimos que es podemos usar **regresion lineal simple** (ya que hay una variable independiente y otra dependiente) para poder resolver nuestro problema.\n",
    "\n",
    "Ahora vamos a armar nuestro modelo, para ello vamos a utilizar el proceso que vimos de Machine Learning\n",
    "\n",
    "![proceso ML](./img/proceso_ml.png)\n",
    "\n",
    "Es decir, necesitaremos datos de entrenamiento y datos de test. Esto se puede hacer facilmente con la libreria **scikit-learn** que nos permite separar nuestros datos para entrenar y para testear el funcionamiento de nuestro modelo.\n",
    "\n",
    "Puedes tambien visitar la pagina de scikit-learn [Aca](https://scikit-learn.org/stable/).\n",
    "\n",
    "Para instalarlo, hacemos \n",
    "\n",
    "```!pip install scikit-learn```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando modulo para separar datos de entrenamiento y testeo de scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos array de Numpy con los features\n",
    "X = dataset.iloc[:,0].values\n",
    "X = X.reshape([-1, 1])\n",
    "# Y con la variable dependendiente (target)\n",
    "y = dataset.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores de X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores de y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de elementos en X y en y\n",
    "print(\"Cantidad de elementos en 'X':\", X.shape)\n",
    "print(\"Cantidad de elementos en 'y':\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset de entrenamiento y testeo. Para este problema usamos el tamaño del test de 30% aprox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de train y de test\n",
    "print(\"Valores de X_train:\",X_train.size)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Valores de X_test:\",len(X_test))\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar el modelo de regresion lineal, la forma de implementarlo usando **scikit-learn**, parametros y formas de uso la podemos encontrar [aca](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el modelo de regresion lineal simple:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regresion = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y lo entrenamos, con el set de entrenamiento\n",
    "regresion.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez entrenado, podemos ver diferente informacion del modelo:\n",
    "\n",
    "print(f\"El valor de la interseccion de la recta sera {regresion.intercept_ }\")\n",
    "print(f\"El valor del coeficiente de la recta sera {regresion.coef_ }\")\n",
    "print(f\"La ecuación de la recta entonces sera la siguiente: y = {regresion.intercept_ }+({regresion.coef_[0]})X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El coeficiente de Pearson es {regresion.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el desvío estándar del modelo\n",
    "std_dev_model = np.sqrt((np.sum((y_train - regresion.predict(X_train))**2))/(y_train.size - 2))\n",
    "print(f\"Desvío estándar del modelo {std_dev_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y si lo graficamos? graficar siempre nos dara una mejor idea de lo que sucede\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('Concentración de droga vs. tiempo', fontsize=16)\n",
    "plt.xlabel('Tiempo [h]', fontsize=14)\n",
    "plt.ylabel('Concentración [mg/L]', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "plt.scatter(X_train, y_train, color='r', marker=\"o\", s=60)\n",
    "plt.plot(X_train, regresion.predict(X_train), color=\"b\", linewidth=2)\n",
    "\n",
    "plt.ylim(0)  # Establece el límite inferior del eje y en cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir X_train en un vector unidimensional\n",
    "X_train = X_train.flatten()\n",
    "\n",
    "# Regresión lineal\n",
    "regression = np.polyfit(X_train, y_train, 1)\n",
    "regression_line = np.polyval(regression, X_train)\n",
    "\n",
    "# Calcular las distancias entre los puntos y la línea de regresión\n",
    "distances = np.abs(regression_line - y_train)\n",
    "\n",
    "# Graficar los puntos\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(X_train, y_train, color='r', s=20)\n",
    "\n",
    "# Graficar la línea de regresión\n",
    "plt.plot(X_train, regression_line, color='b', linewidth=2)\n",
    "\n",
    "# Graficar las líneas perpendiculares desde cada punto a la línea de regresión\n",
    "for x, y, distance in zip(X_train, y_train, distances):\n",
    "    plt.plot([x, x], [y, regression[0]*x + regression[1]], color='black', linestyle='-')\n",
    "    plt.text(x, y, f'{distance:.0f}', ha='left', va=\"baseline\", fontsize=16)\n",
    "\n",
    "# Configuraciones adicionales\n",
    "plt.title(\"Distancia entre la línea de regresión y los puntos\", fontsize=16)\n",
    "plt.xlabel('Tiempo [h]', fontsize=14)\n",
    "plt.ylabel('Concentración [mg/L]', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Metricas\n",
    "\n",
    "Entrenamos el modelo, pero para validar si está bien entrenado, debemos usar el dataset de testeo. \n",
    "\n",
    "Vamos a aplicar las siguientes metricas de evaluación usando scikit-learn:\n",
    "- R2\n",
    "- MAE\n",
    "- MSE\n",
    "- RMSE\n",
    "- MAPE\n",
    "- MPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero obtenemos las predicciones del modelo\n",
    "y_pred = regresion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklean no tiene el error porcentual medio (MPE) lo vamos a crear nosotros\n",
    "def mean_porcentual_error(yreal, ypred):\n",
    "\n",
    "    return np.mean((yreal-ypred)/yreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mpe = mean_porcentual_error(y_test, y_pred)\n",
    "print(\"R-cuadrado en test:\", r2)\n",
    "print(\"Error absoluto medio:\", mae)\n",
    "print(\"Error cuadratico medio:\", mse)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse)\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")\n",
    "print(f\"Error porcentual medio: {mpe*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas no son las unicas métricas que se pueden calcular. Scikit-learn documenta varias [metricas de regresión](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n",
    "\n",
    "Una vez que tenemos el modelo, y estamos conforme, podemos guardarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos utilizar pickle, existen otras herramientas pero con esto bastara.\n",
    "import pickle\n",
    "\n",
    "with open('modelo_regresion_lineal.pkl', 'wb') as archivo:\n",
    "    pickle.dump(regresion, archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos llamarlo para usarlo con otros valores y predecir segun lo que nosotros queremos.\n",
    "\n",
    "with open('modelo_regresion_lineal.pkl', 'rb') as archivo:\n",
    "    modelo_cargado = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasandole nuevos datos a por predecir.....ojo con la forma de pasarlos!\n",
    "X_pred = np.array([ [1], [3.5] ]) # Quiero predecir valores para 1 y 4 horas y media\n",
    "\n",
    "predicciones = modelo_cargado.predict(X_pred) \n",
    "predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Regresión lineal multiple\n",
    "\n",
    "Aunque se uso un ejemplo de una regresión lineal simple, todo lo que vimos sirve exactamente para un problema n-dimensional.\n",
    "\n",
    "Este dataset proviene de [acá](https://www.kaggle.com/datasets/farhanmd29/50-startups). Este conjunto de datos tiene datos recopilados de Nueva York, California y Florida sobre 50 empresas emergentes. Las variables utilizadas en el conjunto de datos son ganancias, gasto en I+D, gasto administrativo y gasto en marketing. \n",
    "\n",
    "Queremos predecir la ganancia usando las otras variables. Pero tenemos un problema inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/50_Startups.csv\") \n",
    "dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que *State* es una variable categorica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"State\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"State\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hacemos para introducir una variable categorica en un modelo matematico? Usando variables Dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_dummies = pd.get_dummies(data=dataset, columns=['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a todo en float\n",
    "dataset_with_dummies = dataset_with_dummies.astype('float')\n",
    "dataset_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto lo pueden hacer tambien con scikit-learn usando LabelEncoder, OneHotEncoder, make_column_transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos una columna de las variables dummy\n",
    "dataset_with_dummies.drop(columns=\"State_New York\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_dummies = dataset_with_dummies[[\"R&D Spend\", \"Administration\", \"Marketing Spend\", \"State_California\", \"State_Florida\", \"Profit\"]]\n",
    "dataset_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver cual es la relacion entre variables, recordemos, es mejor con la variable objetivo, pero malo si es entre variables de entrada....\n",
    "plt.figure(figsize=(7, 5))\n",
    "correlacion_profit = dataset_with_dummies.corr().round(2)\n",
    "sns.heatmap(data=correlacion_profit, annot=True, annot_kws={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=dataset_with_dummies, diag_kind=\"kde\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque tengo muchas variables no significa que debo aplicarla al modelo sin ningun criterio. Como vemos, hay variables que estan correlacionadas que nos pueden dar problemas.\n",
    "\n",
    "Recordemos la maxima: Garbage in + garbage out.\n",
    "\n",
    "Ademas, muchas variables es problema a futuro. Nos puede dificultar los pipelines y hacer mas dificil de entender los datos.\n",
    "\n",
    "### Apliquemos la regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos array de Numpy con los features\n",
    "X = dataset_with_dummies.iloc[:,:-1].values\n",
    "# Y con la variable dependendiente (target)\n",
    "y = dataset_with_dummies.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Dimension de X_train:\",X_train.shape)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Dimension de X_test:\",X_test.shape)\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion = LinearRegression()\n",
    "\n",
    "regresion.fit(X_train, y_train)\n",
    "\n",
    "print(f\"El valor de la interseccion de la recta sera {regresion.intercept_ }\")\n",
    "print(f\"Los valores de los coeficientes de la recta sera {regresion.coef_ }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El coeficiente de Pearson es {regresion.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el desvío estándar del modelo\n",
    "std_dev_model = np.sqrt((np.sum((y_train - regresion.predict(X_train))**2))/(y_train.size-6))\n",
    "print(f\"Desvío estándar del modelo {std_dev_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otenemos las predicciones del modelo\n",
    "y_pred = regresion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mpe = mean_porcentual_error(y_test, y_pred)\n",
    "print(\"R-cuadrado en test:\", r2)\n",
    "print(\"Error absoluto medio:\", mae)\n",
    "print(\"Error cuadratico medio:\", mse)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse)\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")\n",
    "print(f\"Error porcentual medio: {mpe*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Selección de modelo\n",
    "\n",
    "Para seleccionar el modelo vamos a usar otra libreria especializada en herramientas estadisticas, llamada [statsmodels](https://www.statsmodels.org/stable/index.html).\n",
    "\n",
    "Vamos a usar la clase OLS que implementa regresiones lineales ordinarias pero ademas realiza automaticamete el calculo de criterios de selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# El modelo de statsmodel necesita una entrada para el termino independiente.\n",
    "# Para ello vamos a agregar una columna de 1 en la primera columna\n",
    "X_statsmodels = np.append(arr = np.ones((X.shape[0],1)).astype(int), values = X, axis = 1)\n",
    "\n",
    "# Nivel de significancia que vamos a usar\n",
    "SL = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_statsmodels[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar el metodo de construccion de eliminación hacia atrás. Empezamos con el modelo con todas las variables. Para este proceso vamos a usar todo el conjunto de datos.\n",
    "\n",
    "Lo que vamos a seleccionar mediante un test de hipotesis para cada atributo, si el coeficiente es $\\beta_i = 0$ (hipotesis nula). Si no podemos rechazar la hipotesis nula, se elimina el coeficiente. Eliminamos de a una por vez, quitando el peor caso. Para eso ponemos un nivel de significancia de 5%, y el que sobrepase por más distancia a esto, eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X_statsmodels[:, [0, 1, 2, 3, 4, 5]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la variable 4 tiene el mayor nivel de significancia y supera el limite que impusimos de 0.05. La eliminamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X_statsmodels[:, [0, 1, 2, 3, 5]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la variable 5 tiene el mayor nivel de significancia y supera el limite que impusimos de 0.05. La eliminamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X_statsmodels[:, [0, 1, 2, 3]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la variable 2 tiene el mayor nivel de significancia y supera el limite que impusimos de 0.05. La eliminamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X_statsmodels[:, [0, 1, 3]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último paso, ninguna variable esta por encima del nivel de significancia. Entonces elegimos para hacer la regresión a las variables de entradas \"R&D Spend\" y \"Marketing Spend\". Recordemos que eran la que mejor correlación nos daban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos array de Numpy con los features\n",
    "X = dataset_with_dummies[[\"R&D Spend\", \"Marketing Spend\"]].values\n",
    "# Y con la variable dependendiente (target)\n",
    "y = dataset_with_dummies.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Dimension de X_train:\",X_train.shape)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Dimension de X_test:\",X_test.shape)\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion = LinearRegression()\n",
    "\n",
    "regresion.fit(X_train, y_train)\n",
    "\n",
    "print(f\"El valor de la interseccion de la recta sera {regresion.intercept_ }\")\n",
    "print(f\"Los valores de los coeficientes de la recta sera {regresion.coef_ }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El coeficiente de Pearson es {regresion.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el desvío estándar del modelo\n",
    "std_dev_model = np.sqrt((np.sum((y_train - regresion.predict(X_train))**2))/(y_train.size-2))\n",
    "print(f\"Desvío estándar del modelo {std_dev_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otenemos las predicciones del modelo\n",
    "y_pred = regresion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mpe = mean_porcentual_error(y_test, y_pred)\n",
    "print(\"R-cuadrado en test:\", r2)\n",
    "print(\"Error absoluto medio:\", mae)\n",
    "print(\"Error cuadratico medio:\", mse)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse)\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")\n",
    "print(f\"Error porcentual medio: {mpe*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo con el dataset de testing mejoró. Menos variable generaliza mejor.\n",
    "\n",
    "----\n",
    "\n",
    "## Regresión polinómica\n",
    "\n",
    "Para este ejercicio, vamos a usar el dataset de salarios por posición. Es un pequeño ejemplo con pocos datos que nos servira solo a modo de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/position_salaries.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(dataset['Level'], dataset['Salary'] , color='g', marker=\"x\",s=60)\n",
    "plt.grid(True, linewidth=0.5)\n",
    "plt.xlabel(\"Posición del empleado\", fontsize=12)\n",
    "plt.ylabel(\"Sueldo (en $)\", fontsize=12)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "plt.title('Salario vs. nivel de puesto', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "correlacion = dataset[[\"Level\", \"Salary\"]].corr().round(2)\n",
    "sns.heatmap(data=correlacion, annot=True, annot_kws={\"size\": 14});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correlación es bastante alta entre nivel y salario. Un detalle importante, correlación solo mide la relación entre variables como si fuera una relación lineal. Esto nos indica que pese a como se ve el diagrama de dispersión, la componente lineal explica bastante de la relación.\n",
    "\n",
    "Como solo tenemos muy pocos datos, vamos a separar el dataset en testing en una sola observación. Esto es a fines didacticos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos array de Numpy con los features\n",
    "X = dataset.iloc[:,1:-1].values\n",
    "# Y con la variable dependendiente (target)\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1, random_state=42)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Dimension de X_train:\",X_train.shape)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Dimension de X_test:\",X_test.shape)\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos con un modelo lineal\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.scatter(X_test, y_test , color='g', marker=\"x\",s=60)\n",
    "plt.plot(X_train, lin_reg.predict(X_train), color = \"blue\")\n",
    "plt.title(\"Modelo de Regresión Lineal\", fontsize=16)\n",
    "plt.xlabel(\"Posición del empleado\", fontsize=14)\n",
    "plt.ylabel(\"Sueldo (en $)\", fontsize=14);\n",
    "\n",
    "print(f\"El coeficiente de Pearson es {lin_reg.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El módulo de scikit-learn para implementar regresiones polinómicas es [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigamos con un modelo cuadrático\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pol_reg = PolynomialFeatures(degree = 2)\n",
    "# Basicamente nos crea un array con los terminos lineal y cuadraticos\n",
    "X_poly = pol_reg.fit_transform(X_train)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y_train)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "# Creamos valores para poder graficar \"el ajuste\"\n",
    "X_grid = np.arange(np.min(X), np.max(X)+0.1, 0.1)\n",
    "X_grid = X_grid.reshape(len(X_grid), 1)\n",
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.scatter(X_test, y_test , color='g', marker=\"x\",s=60)\n",
    "plt.plot(X_grid, lin_reg_2.predict(pol_reg.fit_transform(X_grid)), color = \"blue\")\n",
    "plt.title(\"Modelo de Regresión Polinomica de orden 2\", fontsize=16)\n",
    "plt.xlabel(\"Posición del empleado\", fontsize=14)\n",
    "plt.ylabel(\"Sueldo (en $)\", fontsize=14);\n",
    "\n",
    "print(f\"El coeficiente de Pearson es {lin_reg_2.score(X_poly, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigamos con un modelo de orden 3\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pol_reg = PolynomialFeatures(degree = 3)\n",
    "# Basicamente nos crea un array con los terminos lineal y cuadraticos\n",
    "X_poly = pol_reg.fit_transform(X_train)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y_train)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "# Creamos valores para poder graficar \"el ajuste\"\n",
    "X_grid = np.arange(np.min(X), np.max(X)+0.1, 0.1)\n",
    "X_grid = X_grid.reshape(len(X_grid), 1)\n",
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.scatter(X_test, y_test , color='g', marker=\"x\",s=60)\n",
    "plt.plot(X_grid, lin_reg_2.predict(pol_reg.fit_transform(X_grid)), color = \"blue\")\n",
    "plt.title(\"Modelo de Regresión Polinomica de orden 3\", fontsize=16)\n",
    "plt.xlabel(\"Posición del empleado\", fontsize=14)\n",
    "plt.ylabel(\"Sueldo (en $)\", fontsize=14);\n",
    "\n",
    "print(f\"El coeficiente de Pearson es {lin_reg_2.score(X_poly, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigamos con un modelo de orden 4\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pol_reg = PolynomialFeatures(degree = 4)\n",
    "# Basicamente nos crea un array con los terminos lineal y cuadraticos\n",
    "X_poly = pol_reg.fit_transform(X_train)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y_train)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "# Creamos valores para poder graficar \"el ajuste\"\n",
    "X_grid = np.arange(np.min(X), np.max(X)+0.1, 0.1)\n",
    "X_grid = X_grid.reshape(len(X_grid), 1)\n",
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.scatter(X_test, y_test , color='g', marker=\"x\",s=60)\n",
    "plt.plot(X_grid, lin_reg_2.predict(pol_reg.fit_transform(X_grid)), color = \"blue\")\n",
    "plt.title(\"Modelo de Regresión Polinomica de orden 4\", fontsize=16)\n",
    "plt.xlabel(\"Posición del empleado\", fontsize=14)\n",
    "plt.ylabel(\"Sueldo (en $)\", fontsize=14);\n",
    "\n",
    "print(f\"El coeficiente de Pearson es {lin_reg_2.score(X_poly, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigamos con un modelo de orden 8\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pol_reg = PolynomialFeatures(degree = 8)\n",
    "# Basicamente nos crea un array con los terminos lineal y cuadraticos\n",
    "X_poly = pol_reg.fit_transform(X_train)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y_train)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "# Creamos valores para poder graficar \"el ajuste\"\n",
    "X_grid = np.arange(np.min(X), np.max(X)+0.1, 0.1)\n",
    "X_grid = X_grid.reshape(len(X_grid), 1)\n",
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.scatter(X_test, y_test , color='g', marker=\"x\",s=60)\n",
    "plt.plot(X_grid, lin_reg_2.predict(pol_reg.fit_transform(X_grid)), color = \"blue\")\n",
    "plt.title(\"Modelo de Regresión Polinomica de orden 8\", fontsize=16)\n",
    "plt.xlabel(\"Posición del empleado\", fontsize=14)\n",
    "plt.ylabel(\"Sueldo (en $)\", fontsize=14);\n",
    "\n",
    "print(f\"El coeficiente de Pearson es {lin_reg_2.score(X_poly, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el polinomio de grado 8 pasa perfectamente por todos los puntos de entrenamiento. Pero si vemos el valor de testing, el modelo predijo muy mal, inclusive predice un absurdo de sueldo negativos.\n",
    "\n",
    "Cuando hablamos de que buscamos generalizar el modelo, hablamos de evitar estos efectos (aqui los exageramos para que sean evidentes). Esto es lo que se llama sobre-ajuste o overfitting, y significa que el modelo se entrenó para que responda muy bien a los datos de entrenamiento, pero es incapaz de predecir correctamente nuevos valores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env_python3_11",
   "language": "python",
   "name": "notebook_env_python3_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
